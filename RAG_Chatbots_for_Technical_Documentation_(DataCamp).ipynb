{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMg/91fFdyA66QmTpD5mT1C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nobobi-Hasan/RAG-Chatbots-for-Technical-Documentation/blob/main/RAG_Chatbots_for_Technical_Documentation_(DataCamp).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project Instructions**\\\n",
        "The car manual HTML document has been loaded for you as 'car_docs'. Using Retrieval Augmented Generation (RAG) to make OpenAI's 'gpt-4o-mini' aware of the contents of 'car_docs', answer the following user query:\n",
        "\n",
        "\"The Gasoline Particular Filter Full warning has appeared. What does this mean and what should I do about it?\"\n",
        "\n",
        "* Store the answer to the user query in the variable 'answer'."
      ],
      "metadata": {
        "id": "sPPOsrG3Lc_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You're working for a well-known car manufacturer who is looking at implementing LLMs into vehicles to provide guidance to drivers. You've been asked to experiment with integrating car manuals with an LLM to create a context-aware chatbot. They hope that this context-aware LLM can be hooked up to a text-to-speech software to read the model's response aloud.\n",
        "\n",
        "As a proof of concept, you'll integrate several pages from a car manual that contains car warning messages and their meanings and recommended actions. This particular manual, stored as an HTML file, `mg-zs-warning-messages.html`, is from an MG ZS automobile, a compact SUV. Armed with your newfound knowledge of LLMs and LangChain, you'll implement Retrieval Augmented Generation (RAG) to create the context-aware chatbot.\n",
        "\n",
        "**Note: Although we'll be using the OpenAI API in this project, you do not need to specify an API key.**"
      ],
      "metadata": {
        "id": "4_Aj9gZ0MCca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install the necessary packages"
      ],
      "metadata": {
        "id": "-ItL8xWsM_nC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to install the necessary packages\n",
        "import subprocess\n",
        "import pkg_resources\n",
        "\n",
        "def install_if_needed(package, version):\n",
        "    '''Function to ensure that the libraries used are consistent to avoid errors.'''\n",
        "    try:\n",
        "        pkg = pkg_resources.get_distribution(package)\n",
        "        if pkg.version != version:\n",
        "            raise pkg_resources.VersionConflict(pkg, version)\n",
        "    except (pkg_resources.DistributionNotFound, pkg_resources.VersionConflict):\n",
        "        subprocess.check_call([\"pip\", \"install\", f\"{package}=={version}\"])\n",
        "\n",
        "install_if_needed(\"langchain-core\", \"0.3.72\")\n",
        "install_if_needed(\"langchain-openai\", \"0.3.28\")\n",
        "install_if_needed(\"langchain-community\", \"0.3.27\")\n",
        "install_if_needed(\"unstructured\", \"0.18.11\")\n",
        "install_if_needed(\"langchain-chroma\", \"0.2.5\")\n",
        "install_if_needed(\"langchain-text-splitters\", \"0.3.9\")"
      ],
      "metadata": {
        "id": "dBVS3GhMMAvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required packages\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_chroma import Chroma"
      ],
      "metadata": {
        "id": "mUtaYah5MMbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "3flU1DYuNIBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the HTML as a LangChain document loader\n",
        "loader = UnstructuredHTMLLoader(file_path=\"data/mg-zs-warning-messages.html\")\n",
        "car_docs = loader.load()"
      ],
      "metadata": {
        "id": "kTpDyO1RMPcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Load the models required to complete the exercise\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])"
      ],
      "metadata": {
        "id": "UInKgAKIMRMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Data"
      ],
      "metadata": {
        "id": "J_MUuoLjMXhD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the loaded document using RecursiveCharacterTextSplitter\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "car_docs_split = text_splitter.split_documents(car_docs)"
      ],
      "metadata": {
        "id": "VmcFBD3aMTNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chroma DB"
      ],
      "metadata": {
        "id": "UjG7dR-cMbDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Chroma vector store from the split documents\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=car_docs_split,\n",
        "    embedding=embeddings,\n",
        "    collection_name=\"mg-zs-warning-messages\"\n",
        ")"
      ],
      "metadata": {
        "id": "hV_8NKuCMg4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Chroma vector retriever for retrieving stroed data\n",
        "retriever = vectorstore.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={'k': 3}\n",
        ")"
      ],
      "metadata": {
        "id": "29R4oYc3MkXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Prompt Template and Chain"
      ],
      "metadata": {
        "id": "BWvd0Oj6Mk16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a chat prompt template for question answering\n",
        "prompt_template = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    You are an assistant knowledgeable about MG ZS warning messages.\n",
        "    Use the following context to answer the user's question.\n",
        "    If the answer cannot be found in the context, say you don't know.\n",
        "\n",
        "    Context:\n",
        "    {context}\n",
        "\n",
        "    Question:\n",
        "    {question}\n",
        "\n",
        "    Answer in a clear and concise manner.\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "aFjVJJvSMnFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Createing the chain\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt_template\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "TRsAeCRoM0sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "9G7sjZd_M2C6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer = chain.invoke(\"The Gasoline Particular Filter Full warning has appeared. What does this mean and what should I do about it?\")\n",
        "\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "MEC1uysiM3Ap"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}